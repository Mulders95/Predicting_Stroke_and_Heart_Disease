{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stroke = pd.read_csv(\"stroke_full_data_cleaned.csv\")\n",
    "df_heart_disease = pd.read_csv(\"heart_disease_full_data_cleaned.csv\")\n",
    "df_hypertension = pd.read_csv(\"hypertension_full_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  hypertension  heart_disease  avg_glucose_level        bmi  stroke  \\\n",
      "0   67             0              1             228.69  36.600000       1   \n",
      "1   61             0              0             202.21  30.007143       1   \n",
      "2   80             0              1             105.92  32.500000       1   \n",
      "3   49             0              0             171.23  34.400000       1   \n",
      "4   79             1              0             174.12  24.000000       1   \n",
      "\n",
      "   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
      "0                   False               True                    False   \n",
      "1                   False              False                     True   \n",
      "2                   False               True                    False   \n",
      "3                   False               True                    False   \n",
      "4                   False              False                     True   \n",
      "\n",
      "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
      "0                            True                        False   \n",
      "1                           False                         True   \n",
      "2                           False                         True   \n",
      "3                           False                        False   \n",
      "4                           False                         True   \n",
      "\n",
      "   smoking_status_smokes  gender_Male  ever_married_Yes  Residence_type_Urban  \n",
      "0                  False         True              True                  True  \n",
      "1                  False        False              True                 False  \n",
      "2                  False         True              True                 False  \n",
      "3                   True        False              True                  True  \n",
      "4                  False        False              True                 False  \n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for categorical features.\n",
    "# One-Hot Encoding using pd.get_dummies.\n",
    "df = pd.get_dummies(df_stroke, columns=['work_type', 'smoking_status', 'gender','ever_married', 'Residence_type'], drop_first=True)\n",
    "\n",
    "# Check the transformed data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the numerical columns (age, avg_glucose_level, and bmi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  avg_glucose_level       bmi\n",
      "0  0.952055           2.532742  0.855424\n",
      "1  0.620984           1.976001 -0.060110\n",
      "2  1.669374          -0.048492  0.286067\n",
      "3 -0.041157           1.324648  0.549916\n",
      "4  1.614196           1.385410 -0.894307\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling on the numerical columns (age, avg_glucose_level, and bmi) using the StandardScaler from the sklearn.preprocessing module. \n",
    "# This is a preprocessing step to standardize the data so that each feature has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale numerical features: age, avg_glucose_level, bmi\n",
    "df[['age', 'avg_glucose_level', 'bmi']] = scaler.fit_transform(df[['age', 'avg_glucose_level', 'bmi']])\n",
    "\n",
    "# Check the scaled data\n",
    "print(df[['age', 'avg_glucose_level', 'bmi']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi',\n",
       "       'stroke', 'work_type_Never_worked', 'work_type_Private',\n",
       "       'work_type_Self-employed', 'smoking_status_formerly smoked',\n",
       "       'smoking_status_never smoked', 'smoking_status_smokes', 'gender_Male',\n",
       "       'ever_married_Yes', 'Residence_type_Urban'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training and testing set. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('stroke', axis=1), df[\"stroke\"], train_size=0.75, shuffle=True, stratify=df[\"stroke\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 3049, 1: 185})\n",
      "After SMOTE: Counter({0: 3049, 1: 3049})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Create an instance of SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after resampling\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "print(\"After SMOTE:\", Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1017\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.94      1079\n",
      "   macro avg       0.47      0.50      0.49      1079\n",
      "weighted avg       0.89      0.94      0.91      1079\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1017    0]\n",
      " [  62    0]]\n",
      "ROC AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      1017\n",
      "           1       0.13      0.68      0.22        62\n",
      "\n",
      "    accuracy                           0.72      1079\n",
      "   macro avg       0.55      0.70      0.52      1079\n",
      "weighted avg       0.93      0.72      0.80      1079\n",
      "\n",
      "Confusion Matrix:\n",
      "[[736 281]\n",
      " [ 20  42]]\n",
      "ROC AUC: 0.7005582516573097\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83      1017\n",
      "           1       0.14      0.73      0.23        62\n",
      "\n",
      "    accuracy                           0.72      1079\n",
      "   macro avg       0.56      0.73      0.53      1079\n",
      "weighted avg       0.93      0.72      0.80      1079\n",
      "\n",
      "Confusion Matrix:\n",
      "[[737 280]\n",
      " [ 17  45]]\n",
      "ROC AUC: 0.7252434421289689\n"
     ]
    }
   ],
   "source": [
    "model_new = LogisticRegression(class_weight=\"balanced\")\n",
    "model_new.fit(X_train, y_train)\n",
    "y_pred = model_new.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100, class_weight='balanced')\n",
    "\n",
    "# Train (fit) the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.016216216216216217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',           \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)  \n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100, class_weight='balanced')\n",
    "\n",
    "# Train (fit) the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1017\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.94      1079\n",
      "   macro avg       0.47      0.50      0.48      1079\n",
      "weighted avg       0.89      0.94      0.91      1079\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1015    2]\n",
      " [  62    0]]\n",
      "ROC AUC: 0.49901671583087515\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.00\n",
      "Recall:    0.00\n",
      "F1-score:  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1-score:  {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "brf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = brf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81      1017\n",
      "           1       0.13      0.74      0.22        62\n",
      "\n",
      "    accuracy                           0.70      1079\n",
      "   macro avg       0.55      0.72      0.51      1079\n",
      "weighted avg       0.93      0.70      0.78      1079\n",
      "\n",
      "Confusion Matrix:\n",
      "[[704 313]\n",
      " [ 16  46]]\n",
      "ROC AUC: 0.7170837694674407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
